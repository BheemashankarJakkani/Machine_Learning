{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"E:\\Edu\\Data Science and ML\\Machinelearningaz\\Datasets\\Part 1 - Data Preprocessing\\\\Data.csv\")\n",
    "print(dataset)\n",
    "\n",
    "X=dataset.iloc[:,:-1].values    #Takes all values except last colum values  (Matrix)\n",
    "y=dataset.iloc[:,-1:].values    #Take last colum values   (Vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Care of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jakkani\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Removing the missing data quite dangerous Because we will loose crucial information\n",
    "#Take the mean of the colum\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer=Imputer(missing_values='NaN',strategy='mean',axis=0)   #Replace missing values NaN with mean and along the colums(axis=0)\n",
    "imputer=imputer.fit(X[:, 1:3])   #fit the Imputer obj to the Matrix X\n",
    "X[:, 1:3]=imputer.transform(X[:,1:3])   #It replace sthe misiisng data with the mean of the column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.40000000e+01 7.20000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 2.70000000e+01 4.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 3.00000000e+01 5.40000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.80000000e+01 6.10000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 4.00000000e+01 6.37777778e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.50000000e+01 5.80000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.00000000e+00 3.87777778e+01 5.20000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.80000000e+01 7.90000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      "  0.00000000e+00 5.00000000e+01 8.30000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.70000000e+01 6.70000000e+04]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jakkani\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Jakkani\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "labelencoder_X=LabelEncoder()    #Create Object\n",
    "X[:,0]=labelencoder_X.fit_transform(X[:,0])    #We should label 0th column data \n",
    "\n",
    "#Encoding Dummmy variables ,  Becoz the machine learning model dont think about the Encodedvalues as  like  size etc \n",
    "onehotencoder=OneHotEncoder(categorical_features= [0])  \n",
    "X=onehotencoder.fit_transform(X).toarray()\n",
    "print(X)\n",
    "labelencoder_y=LabelEncoder()    #Create Object\n",
    "y=labelencoder_y.fit_transform(y)    \n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Dataset into TrainingSet and TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)   #testset 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "X_train=sc_X.fit_transform(X_train)\n",
    "X_test=sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        ,  1.        , -1.        ,  2.64575131, -0.77459667,\n",
       "         0.26306757,  0.12381479],\n",
       "       [ 1.        , -1.        ,  1.        , -0.37796447, -0.77459667,\n",
       "        -0.25350148,  0.46175632],\n",
       "       [-1.        ,  1.        , -1.        , -0.37796447,  1.29099445,\n",
       "        -1.97539832, -1.53093341],\n",
       "       [-1.        ,  1.        , -1.        , -0.37796447,  1.29099445,\n",
       "         0.05261351, -1.11141978],\n",
       "       [ 1.        , -1.        ,  1.        , -0.37796447, -0.77459667,\n",
       "         1.64058505,  1.7202972 ],\n",
       "       [-1.        ,  1.        , -1.        , -0.37796447,  1.29099445,\n",
       "        -0.0813118 , -0.16751412],\n",
       "       [ 1.        , -1.        ,  1.        , -0.37796447, -0.77459667,\n",
       "         0.95182631,  0.98614835],\n",
       "       [ 1.        , -1.        ,  1.        , -0.37796447, -0.77459667,\n",
       "        -0.59788085, -0.48214934]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
